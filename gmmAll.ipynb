{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gmmAll.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"2whb6qvLa13Y","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import librosa\n","import glob\n","import numpy as np\n","from joblib import dump, load\n","from sklearn.mixture import GaussianMixture\n","from sklearn.metrics import roc_curve"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qm-Fk3W8alKX","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","class voice_processor():\n","  \"\"\"\n","  provides functions for loading wav files and extracting MFCCs:\n","  \n","  getMFCCsDF: method\n","    Loads the audio in the filename and extracts the MFCCs of the audio. \n","  getMFCCsDF_batch: method\n","    Loads all audio in a folder and extracts the MFCCs of each audio.\n","  \n","  \"\"\"\n","  \n","  def __init__(self):\n","    \"\"\"Inits voice processor\n","    \"\"\"\n","    self.author='Ching Pui WAN'\n","    self.author_contact='cpwan@ust.hk'\n","    \n","  def getMFCCsDF(self,filename,speakerId):\n","\n","    \"\"\" Loads the audio in the filename and extracts the MFCCs of the audio. \n","      The MFCCs is returned as a dataframe.\n","\n","      Args:\n","          filename:  string\n","            The path to the audio. \n","            For example, 'wav/id10277/tbh20gz_KRA/00007.wav'\n","          speakerId: string\n","            The speaker id to be included in the output dataframe. \n","            For example, 'id10277'\n","      Returns:\n","          A dataframe of the MFCCs with the metadata. Each row of the dataframe \n","          corresponds to a speech segment, and consists of 20 MFCCs, the filename, \n","          and the speaker id w.r.t to the audio. For example:\n","\n","          columns: 0,1,2,...18,19,filename,speakerId\n","    \"\"\"\n","\n","    y, sr = librosa.load(filename)\n","    mfccs=librosa.feature.mfcc(y,sr)\n","    tempDF=pd.DataFrame(mfccs.T)\n","    tempDF['filename']=filename\n","    tempDF['speakerId']=speakerId\n","    out=tempDF\n","    return out\n","\n","  def getMFCCsDF_batch(self,folder,speakerId):\n","  \n","  \n","    \"\"\" Loads all audio in a folder and extracts the MFCCs of each audio. \n","        The MFCCs is concatenated as a dataframe.\n","\n","      Args:\n","          folder:  string\n","            The path to the folder containing subfolder of audios. \n","            For example, folder='wav/id10270'. Then all the wav files in \n","            'wav/id10270/**/' will be loaded\n","          speakerId: string\n","            The speaker id to be included in the output dataframe. \n","            For example, 'id10270'\n","      Returns:\n","          A dataframe of the MFCCs with the metadata. Each row of the dataframe \n","          corresponds to a speech segment, and consists of 20 MFCCs, the filename, \n","          and the speaker id w.r.t to the audio. For example:\n","\n","          columns: 0,1,2,...18,19,filename,speakerId\n","    \"\"\"\n","  \n","    DF=pd.DataFrame([])\n","    print('Processing speaker %s'%speakerId)\n","    files = glob.glob('%s/**/*.wav'%folder, recursive=True)\n","    \n","    count=0\n","    for filename in files:\n","      if count%50==0:\n","        print('Extracted %d / %d files'%(count,len(files)))\n","      DF=DF.append(self.getMFCCsDF(filename,speakerId))\n","      count=count+1\n","    print('Finished extracting features for %s'%speakerId)\n","    DF.reset_index(drop=True,inplace=True)\n","    out=DF\n","    return out\n","  \n","  def getFeature_batch(self,folder,speakerId):\n","    out=self.getMFCCsDF_batch(folder,speakerId)\n","    return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"p4N6TdZaav3C","colab_type":"code","colab":{}},"cell_type":"code","source":["class GMM_UBM():\n","  \"\"\"Summary of class here.\n","\n","  Longer class information....\n","  Longer class information....\n","\n","  Attributes:\n","      speaker_Ids: \n","        A list of strings to index the speaker\n","      audio_folders: \n","        A dict, in the form of {speaker_id: 'path/to/folder'}\n","      feature_dict: \n","        A dict of dataframe w.r.t. each speaker, \n","        in the form of {speaker_id: dataframe}\n","      processor: \n","        A class where the feature extraction methods are.\n","      feature_out_format: \n","        A string to indicate the path to store the extracted features.For \n","        example, feature_out_format='feature_%s.joblib', for which %s would \n","        correspond to the speaker id.\n","  \"\"\"\n","  \n","  \n","  def __init__(self):\n","    \"\"\"Inits GMM_UBM.\n","    \"\"\"\n","    self.path=''\n","    self.speaker_Ids=[]\n","    self.train_speaker_Ids=[]\n","    self.test_speaker_Ids=[]\n","    self.audio_folders={}\n","    self.feature_dict={}\n","    self.processor=voice_processor()\n","    self.feature_out_format='feature/feature_%s.joblib'\n","    self.ubm=None\n","    self.ubm_out_name='ubm/ubm.joblib'\n","    self.speaker_models={}\n","    self.speaker_model_out_format='speaker_model/speaker_model_%s.joblib'\n","    \n","  def init_ubm(self,n_components=64):\n","    self.ubm=GaussianMixture(n_components=n_components,covariance_type='diag')\n","    print('Initialized the Gaussian Mixture Model for UBM with %d components'%n_components)\n","    \n","    \n","  def process(self):\n","    \"\"\"\n","    Extracts features for each speaker. \n","      This method extracts all the wavs file in self.audio_folders for each \n","      speaker using the method in self.processor. The features are then dumped \n","      to disk with the filename specified by self.feature_out_format.\n","      \n","      Remarks: this method overwrites the exisiting files.\n","    \"\"\"\n","    speaker_Ids=self.speaker_Ids\n","    folders=self.audio_folders\n","    feature_out_format=self.feature_out_format\n","    \n","    for speaker_Id in speaker_Ids:\n","      folder= folders[speaker_Id]\n","      df=self.processor.getFeature_batch(folder,speaker_Id)\n","      \n","      #save the feature dataframe in memory\n","      self.feature_dict[speaker_Id]=df\n","      \n","      #save the features to disk\n","      output_name=feature_out_format%speaker_Id\n","      dump(df,output_name)\n","      print('Saved feature to %s.'%output_name)\n","\n","  def process_new(self):\n","    \"\"\"\n","    Extracts features for each speaker. \n","      This method extracts all the wavs file in self.audio_folders for each \n","      speaker using the method in self.processor. The features are then dumped \n","      to disk with the filename specified by self.feature_out_format.\n","    \"\"\"\n","    speaker_Ids=self.speaker_Ids\n","    folders=self.audio_folders\n","    feature_out_format=self.feature_out_format\n","    feature_dict=self.feature_dict\n","    \n","    for speaker_Id in speaker_Ids:\n","      if speaker_Id in feature_dict:\n","        print('Speaker %s already processed. Check feature_dict.'%speaker_Id)\n","        continue\n","      folder= folders[speaker_Id]\n","      df=self.processor.getFeature_batch(folder,speaker_Id)\n","      \n","      #save the feature dataframe in memory\n","      self.feature_dict[speaker_Id]=df\n","      \n","      #save the features to disk\n","      output_name=feature_out_format%speaker_Id\n","      dump(df,output_name)\n","      print('Saved feature to %s.'%output_name)\n","      \n","  def load_feature_from_disk(self):\n","    \"\"\"\n","    Loads features for each speaker from disk.\n","      This method loads the features for all speaker in the speaker_Ids from \n","      the path specified by self.feature_out_format.\n","    \"\"\"\n","  \n","    feature_out_format=self.feature_out_format\n","    speaker_Ids=self.speaker_Ids\n","    \n","    for speaker_Id in speaker_Ids:\n","      try:\n","        df=load(feature_out_format%speaker_Id)\n","        self.feature_dict[speaker_Id]=df\n","      except:\n","        print('Feature of Speaker %s not found in disk.' %speaker_Id)\n","      \n","  def get_balanced_data(self,X,y):\n","    \"\"\"\n","    Oversamples the minority to balance the classes.\n","      Dependency: imbalanced-learn\n","    \"\"\"\n","    from imblearn.over_sampling import RandomOverSampler\n","    ros = RandomOverSampler(random_state=0)\n","    X_resampled, y_resampled = ros.fit_resample(X, y)\n","    return X_resampled, y_resampled\n","    \n","  def train_ubm(self):\n","    \n","    \"\"\"\n","    Trains the gaussian mixture model for the universal background model by \n","    concatenating the features of each speech segments.\n","    \"\"\"\n","    train_speaker_Ids=self.train_speaker_Ids\n","    feature_dict=self.feature_dict\n","    \n","    #prepare the dataframe feeding to gmm\n","    listOfDF=[feature_dict[speaker_Id] for speaker_Id in train_speaker_Ids]\n","    DF=pd.concat(listOfDF)\n","    DF.reset_index(drop=True,inplace=True)\n","    X=DF[[i for i in DF.columns if i not in ['filename','speakerId']]]\n","    y=DF['speakerId']\n","    X,y=self.get_balanced_data(X,y)\n","    if self.ubm==None:\n","      self.init_ubm()\n","    self.ubm.fit(X)\n","    \n","  def save_ubm_to_disk(self):\n","    ubm=self.ubm\n","    ubm_out_name=self.ubm_out_name\n","    \n","    dump(ubm, ubm_out_name) \n","  def load_ubm_from_disk(self):\n","    ubm_out_name=self.ubm_out_name\n","\n","    ubm=load(ubm_out_name)\n","    self.ubm=ubm\n","\n","  def enroll_speaker(self,speakerId):\n","    \"\"\"\n","    Enrolls the speaker by building the speaker model.\n","      1.) Must run self.process or self.process_new in advance to extract \n","      feature and store feature in self.feature_dict.\n","      2.) Must train the ubm in advance. Run self.train_ubm or self.load_ubm_from_disk.\n","    \n","    \"\"\"\n","\n","    feature_dict=self.feature_dict\n","    ubm=self.ubm\n","    \n","    n_components=ubm.n_components\n","    weights=ubm.weights_\n","    means=ubm.means_\n","    precisions=ubm.precisions_#this is the inverse of the covariance matrix\n","    \n","    if speakerId in feature_dict:\n","      gmm=GaussianMixture(n_components=n_components,\n","                                  covariance_type='diag',\n","                                  weights_init=weights,\n","                                  means_init=means,\n","                                  precisions_init=precisions)\n","      DF=feature_dict[speakerId]\n","      X=DF[[i for i in DF.columns if i not in ['filename','speakerId']]]\n","      gmm.fit(X.values)\n","      self.speaker_models[speakerId]=gmm\n","    else:\n","      print('Please first extract the feature of speaker %s using process() or process_new()'%speakerId)\n","      \n","  def save_speaker_model(self):\n","    speaker_models=self.speaker_models\n","    speaker_model_out_format=self.speaker_model_out_format\n","    \n","    for (speakerId,model) in speaker_models.items():\n","      dump(model,speaker_model_out_format%speakerId)\n","      \n","  def load_speaker_model(self,speakerId):\n","    speaker_model_out_format=self.speaker_model_out_format\n","    out=None\n","    try:\n","      out=load(speaker_model_out_format%speakerId)\n","      self.speaker_models[speakerId]=out\n","    except:\n","      print('Speaker model not found in disk')\n","    finally:\n","      return out\n","  def score_pairwise(self,speakerId,speakerId_test):\n","    \"\"\"\n","    Tests if the speech in speakerId_test is spoken by speakerId.\n","    \n","      Args:\n","        speakerId: string\n","          The speaker to be tested on.\n","        speakerId_test: string\n","          Speaker id w.r.t the test set.\n","          \n","      Returns:\n","        A dataframe of the mean log likelihood ratio score of test sample w.r.t the \n","        speaker specified by speakerId. It has the following coloums:\n","        \n","          filename, speakerId, score\n","\n","    \"\"\"\n","    if speakerId_test not in self.feature_dict:\n","      raise KeyError('Feature of speaker %s not initialized'%speakerId_test)\n","    if speakerId not in self.speaker_models:\n","      raise KeyError('Speaker model for speaker %s not initialized'%speakerId)\n","    \n","    testDF=self.feature_dict[speakerId_test]\n","    speaker_model=self.speaker_models[speakerId]\n","    ubm=self.ubm\n","    \n","    X=testDF[[i for i in testDF.columns if i not in ['filename','speakerId']]]\n","    metaData=testDF[['filename','speakerId']]\n","    scoreDF=metaData.copy()\n","    #gmm.score_smaples give the log likelihood\n","    scoreDF['score']=speaker_model.score_samples(X)-ubm.score_samples(X)\n","    out=scoreDF.groupby(['filename','speakerId']).mean()\n","    return out\n","  \n","  def test_wrt_speaker(self,speakerId,positive_speaker_id,negative_speaker_ids):\n","    \"\"\"\n","    Tests the performance of the verification system.\n","      W.r.t the speaker specified by speakerId, evaluates the log likelihood ratio\n","      for positive and negative samples.\n","    \n","    Args:\n","      speakerId: string\n","        The speaker to be tested on.\n","      positive_speaker_id: string\n","        Speaker id w.r.t the positive test set of the same speaker.\n","      negative_speaker_ids: a list of string\n","        Speaker ids w.r.t the negative test set containing speeces of other speakers.  \n","    Returns:\n","      A tuple of (DF,fpr,fnr,eer),\n","      DF is a dataframe of the log likelihood ratio score for each audio file, \n","      it has columns: filename, speakerId, score, y_true. 'y_true' indicates \n","      whether the audio is positive or negative sample. \n","      fpr,fnr are the false postive rate and false negative rate under different \n","      threshold of log likelihood ratio score.\n","      eer is the equal error rate.\n","\n","    \"\"\"\n","    score=self.score_pairwise\n","    \n","    listDF=[]\n","    pos_df=score(speakerId,positive_speaker_id)\n","    pos_df['y_true']=np.ones(len(pos_df))\n","    listDF.append(pos_df)\n","    \n","    for neg_speaker_id in negative_speaker_ids:\n","      neg_df=score(speakerId,neg_speaker_id)\n","      neg_df['y_true']=np.zeros(len(neg_df))\n","      listDF.append(neg_df)\n","    DF=pd.concat(listDF)\n","    DF.reset_index(drop=True,inplace=True)\n","    y_true=DF['y_true']\n","    y_score=DF['score']\n","    \n","    \n","    \n","    fpr, tpr, threshold = roc_curve(y_true, y_score, pos_label=1)\n","    fnr = 1 - tpr\n","    eer=(fpr[np.argmin(np.abs(fpr-fnr))]+fnr[np.argmin(np.abs(fpr-fnr))])/2\n","    print('EER for speaker %s = %.4f'%(speakerId,eer))\n","    return DF,fpr,fnr,eer"],"execution_count":0,"outputs":[]}]}